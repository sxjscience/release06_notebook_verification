{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26f63abc",
   "metadata": {},
   "source": [
    "# AutoMM Detection - Prepare COCO2017 Dataset\n",
    ":label:`sec_automm_detection_prepare_coco17`\n",
    "\n",
    "[COCO](https://cocodataset.org/#home) is a large-scale object detection, segmentation, and captioning dataset. \n",
    "For detection, the most commonly used version is COCO2017 with the largest number of training data.\n",
    "There are 80 classes, 123,287 images, 886,284 instances, and the median image ratio is 640 x 480.\n",
    "This tutorial will walk through the steps of preparing this dataset for Autogluon MultiModalPredictor.\n",
    "\n",
    "You need 42.7 GB disk space to download and extract this dataset. SSD is preferred over HDD because of its better performance.\n",
    "The total time to prepare the dataset depends on your Internet speed and disk performance. For example, it often takes 20 min on AWS EC2 with EBS.\n",
    "\n",
    "COCO has an [official download page](https://cocodataset.org/#download), \n",
    "but it's always easier to perform a one-step setup.\n",
    "We prepared a bash script for one-step downloading the COCO17 dataset: \n",
    "[download_coco17.sh](https://raw.githubusercontent.com/awslabs/autogluon/master/examples/automm/object_detection/download_coco17.sh).\n",
    "Or you can also use our cli tool `prepare_detection_dataset` that can download all datasets mentioned in our tutorials.\n",
    "This python script is in our code: \n",
    "[prepare_detection_dataset.py](https://github.com/awslabs/autogluon/tree/master/autogluon/multimodal/src/autogluon/multimodal/cli/prepare_detection_dataset.py),\n",
    "and you can also run it as a cli: `python3 -m autogluon.multimodal.cli.prepare_detection_dataset`.\n",
    "\n",
    "### Download with Python Script\n",
    "\n",
    "The python script does not show progress bar, but is promised to work on all major platforms.\n",
    "If you are working on a Unix system and needs a progress bar, try the bash script!\n",
    "\n",
    "You could either extract it in coco17 folder under current directory by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce12d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 -m autogluon.multimodal.cli.prepare_detection_dataset --dataset_name coco2017"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b1770d",
   "metadata": {},
   "source": [
    "or extract it in coco17 folder under a provided output path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00de020",
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 -m autogluon.multimodal.cli.prepare_detection_dataset --dataset_name coco2017 --output_path ~/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386d535d",
   "metadata": {},
   "source": [
    "or make it shorter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b697e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 -m autogluon.multimodal.cli.prepare_detection_dataset -d coco17 -o ~/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9edf4c",
   "metadata": {},
   "source": [
    "### Download with Bash Script\n",
    "\n",
    "You could either extract it in coco17 folder under current directory by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795fd5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "bash download_coco17.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81b1016",
   "metadata": {},
   "source": [
    "or extract it in coco17 folder under a provided output path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ba11bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bash download_coco17.sh ~/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0011ccf",
   "metadata": {},
   "source": [
    "The command line output will show the progress bar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1832648",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract data in ./coco17\n",
    "--2022-11-02 20:19:49--  http://images.cocodataset.org/zips/train2017.zip\n",
    "Resolving images.cocodataset.org (images.cocodataset.org)... 52.217.18.68\n",
    "Connecting to images.cocodataset.org (images.cocodataset.org)|52.217.18.68|:80... connected.\n",
    "HTTP request sent, awaiting response... 200 OK\n",
    "Length: 19336861798 (18G) [application/zip]\n",
    "Saving to: ‘train2017.zip’\n",
    "\n",
    "train2017.zip                          100%[=========================================================================>]  18.01G  27.0MB/s    in 7m 29s  \n",
    "\n",
    "2022-11-02 20:27:18 (41.1 MB/s) - ‘train2017.zip’ saved [19336861798/19336861798]\n",
    "\n",
    "--2022-11-02 20:27:18--  http://images.cocodataset.org/zips/val2017.zip\n",
    "Resolving images.cocodataset.org (images.cocodataset.org)... 54.231.171.137\n",
    "Connecting to images.cocodataset.org (images.cocodataset.org)|54.231.171.137|:80... connected.\n",
    "HTTP request sent, awaiting response... 200 OK\n",
    "Length: 815585330 (778M) [application/zip]\n",
    "Saving to: ‘val2017.zip’\n",
    "\n",
    "val2017.zip                            100%[=========================================================================>] 777.80M  43.0MB/s    in 20s     \n",
    "\n",
    "2022-11-02 20:27:38 (39.2 MB/s) - ‘val2017.zip’ saved [815585330/815585330]\n",
    "\n",
    "--2022-11-02 20:27:38--  http://images.cocodataset.org/zips/test2017.zip\n",
    "Resolving images.cocodataset.org (images.cocodataset.org)... 54.231.162.177\n",
    "Connecting to images.cocodataset.org (images.cocodataset.org)|54.231.162.177|:80... connected.\n",
    "HTTP request sent, awaiting response... 200 OK\n",
    "Length: 6646970404 (6.2G) [application/zip]\n",
    "Saving to: ‘test2017.zip’\n",
    "\n",
    "test2017.zip                           100%[=========================================================================>]   6.19G  42.3MB/s    in 2m 32s  \n",
    "\n",
    "2022-11-02 20:30:11 (41.6 MB/s) - ‘test2017.zip’ saved [6646970404/6646970404]\n",
    "\n",
    "--2022-11-02 20:30:11--  http://images.cocodataset.org/zips/unlabeled2017.zip\n",
    "Resolving images.cocodataset.org (images.cocodataset.org)... 52.217.71.116\n",
    "Connecting to images.cocodataset.org (images.cocodataset.org)|52.217.71.116|:80... connected.\n",
    "HTTP request sent, awaiting response... 200 OK\n",
    "Length: 20126613414 (19G) [application/zip]\n",
    "Saving to: ‘unlabeled2017.zip’\n",
    "\n",
    "unlabeled2017.zip                       33%[========================>                                                 ]   6.37G  43.2MB/s    eta 5m 45s "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2da4c7",
   "metadata": {},
   "source": [
    "And after it finished, in coco17 folder it contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b8f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations  test2017  train2017  unlabeled2017  val2017"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93caece1",
   "metadata": {},
   "source": [
    "### The COCO Format\n",
    "\n",
    "COCO also refers to the specific format (in `.json` file) the COCO dataset is using.\n",
    "In Autogluon MultiModalPredictor, we strongly recommend using this as your data format.\n",
    "Check :ref:`sec_automm_detection_convert_to_coco` and :ref:`sec_automm_detection_voc_to_coco` for more information\n",
    "about create a COCO format dataset from scratch or from other format, especially VOC format.\n",
    "\n",
    "### Other Examples\n",
    "\n",
    "You may go to [AutoMM Examples](https://github.com/awslabs/autogluon/tree/master/examples/automm) to explore other examples about AutoMM.\n",
    "\n",
    "### Customization\n",
    "To learn how to customize AutoMM, please refer to :ref:`sec_automm_customization`.\n",
    "\n",
    "### Citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d06fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@misc{https://doi.org/10.48550/arxiv.1405.0312,\n",
    "  doi = {10.48550/ARXIV.1405.0312},\n",
    "  url = {https://arxiv.org/abs/1405.0312},\n",
    "  author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Bourdev, Lubomir and Girshick, Ross and Hays, James and Perona, Pietro and Ramanan, Deva and Zitnick, C. Lawrence and Dollár, Piotr},\n",
    "  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},\n",
    "  title = {Microsoft COCO: Common Objects in Context},\n",
    "  publisher = {arXiv},\n",
    "  year = {2014},\n",
    "  copyright = {arXiv.org perpetual, non-exclusive license}\n",
    "}"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
