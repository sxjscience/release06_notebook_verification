{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f66f334",
   "metadata": {},
   "source": [
    "# AutoMM Detection - Evaluate Pretrained Faster R-CNN on VOC Format Dataset\n",
    ":label:`sec_automm_detection_eval_fasterrcnn_voc`\n",
    "\n",
    "In this section, our goal is to evaluate Faster-RCNN model on VOC2007 dataset in VOC format.\n",
    "See \\[Convert VOC to COCO] for how to quickly convert a VOC format dataset.\n",
    "In previous section :ref:`sec_automm_detection_eval_fasterrcnn_coco`, we evaluated Faster-RCNN on COCO dataset.\n",
    "We strongly recommend using COCO format, but AutoMM still have limited support for VOC format for quick proof testing.\n",
    "\n",
    "To start, let's import MultiModalPredictor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc53ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aee062c",
   "metadata": {},
   "source": [
    "We use the Faster R-CNN with ResNet50 as backbone and Feature Pyramid Network (FPN) as neck.\n",
    "This is the only model we support that is pretrained on VOC.\n",
    "It's always recommended to finetune a model pretrained on COCO which is a larger dataset with more complicated task.\n",
    "To test other model structures on VOC, check \\[Fast Finetune on COCO format data] and \\[Fast Finetune on VOC format data]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c82949",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = \"faster_rcnn_r50_fpn_1x_voc0712\"\n",
    "num_gpus = 1  # multi GPU inference is not supported in VOC format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd127c0",
   "metadata": {},
   "source": [
    "As before, we create the MultiModalPredictor with selected checkpoint name and number of GPUs.\n",
    "We also need to specify the problem_type to `\"object_detection\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c9ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = MultiModalPredictor(\n",
    "    hyperparameters={\n",
    "        \"model.mmdet_image.checkpoint_name\": checkpoint_name,\n",
    "        \"env.num_gpus\": num_gpus,\n",
    "    },\n",
    "    problem_type=\"object_detection\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3090457",
   "metadata": {},
   "source": [
    "Here we use VOC2007 for testing: \\[Prepare VOC Dataset].\n",
    "While using VOC format dataset, the input is the root path of the dataset, and contains at least:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18933a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Annotations  ImageSets  JPEGImages labels.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c241ced",
   "metadata": {},
   "source": [
    "Here `labels.txt` shall be added manually to include all the labels in the dataset. \n",
    "In this example, the content of `labels.txt` is shown as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5460759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aeroplane\n",
    "bicycle\n",
    "bird\n",
    "boat\n",
    "bottle\n",
    "bus\n",
    "car\n",
    "cat\n",
    "chair\n",
    "cow\n",
    "diningtable\n",
    "dog\n",
    "horse\n",
    "motorbike\n",
    "person\n",
    "pottedplant\n",
    "sheep\n",
    "sofa\n",
    "train\n",
    "tvmonitor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1c2b14",
   "metadata": {},
   "source": [
    "For VOC format data, we always use root_path. And the predictor will automatically select the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28feb4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"VOCdevkit/VOC2007\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9521a1",
   "metadata": {},
   "source": [
    "To evaluate the pretrained Faster R-CNN model we loaded, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea0f62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predictor.evaluate(test_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d082012b",
   "metadata": {},
   "source": [
    "Here the test set is selected automatically in `predictor.evaluate`.\n",
    "And if we `print(result)`, the first value `0.4406` is mAP in COCO standard, and the second one `0.7328` is mAP in VOC standard (or mAP50). For more details about these metrics, see [COCO's evaluation guideline](https://cocodataset.org/#detection-eval)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e8ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'map': tensor(0.4406), 'map_50': tensor(0.7328), 'map_75': tensor(0.4658), 'map_small': tensor(0.0959), 'map_medium': tensor(0.3085), 'map_large': tensor(0.5281), 'mar_1': tensor(0.3761), 'mar_10': tensor(0.5297), 'mar_100': tensor(0.5368), 'mar_small': tensor(0.1485), 'mar_medium': tensor(0.4192), 'mar_large': tensor(0.6328), 'map_per_class': tensor(-1.), 'mar_100_per_class': tensor(-1.)}\n",
    "time usage: 533.67"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab8a9f7",
   "metadata": {},
   "source": [
    "### Other Examples\n",
    "\n",
    "You may go to [AutoMM Examples](https://github.com/awslabs/autogluon/tree/master/examples/automm) to explore other examples about AutoMM.\n",
    "\n",
    "### Customization\n",
    "To learn how to customize AutoMM, please refer to :ref:`sec_automm_customization`.\n",
    "\n",
    "### Citation\n",
    "```\n",
    "@article{Ren_2017,\n",
    "   title={Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},\n",
    "   journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},\n",
    "   publisher={Institute of Electrical and Electronics Engineers (IEEE)},\n",
    "   author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},\n",
    "   year={2017},\n",
    "   month={Jun},\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
