{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceac45b8",
   "metadata": {},
   "source": [
    "# AutoMM Detection - Evaluate Pretrained YOLOv3 on COCO Format Dataset\n",
    ":label:`sec_automm_detection_eval_yolov3_coco`\n",
    "\n",
    "In this section, our goal is to evaluate YOLOv3 model on COCO17 dataset in COCO format. We start with yolov3 because it's extremely fast and accurate, and is a good choice to deploy with strict time and computational restrictions.\n",
    "\n",
    "To start, let's import MultiModalPredictor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a8ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d4c6dd",
   "metadata": {},
   "source": [
    "We select the YOLOv3 with MobileNetV2 as backbone, \n",
    "this model reached **85.0 Frames Per Second (FPS)** on single A10e GPU with `batch_size=1`.\n",
    "For details about model selection, see :ref:`sec_automm_detection_select_models`.\n",
    "And we use all the GPUs (if any):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8898be89",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = \"yolov3_mobilenetv2_320_300e_coco\"\n",
    "num_gpus = -1  # use all GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d82f81a",
   "metadata": {},
   "source": [
    "We create the MultiModalPredictor with selected checkpoint name and number of GPUs.\n",
    "We also need to specify the problem_type to `\"object_detection\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904dc334",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = MultiModalPredictor(\n",
    "    hyperparameters={\n",
    "        \"model.mmdet_image.checkpoint_name\": checkpoint_name,\n",
    "        \"env.num_gpus\": num_gpus,\n",
    "    },\n",
    "    problem_type=\"object_detection\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c568e4",
   "metadata": {},
   "source": [
    "Here we use COCO17 for testing. \n",
    "See other tutorials for \\[Prepare COCO2017], \\[Convert VOC Format Dataset to COCO Format], and \\[Create Custom Dataset].\n",
    "While using COCO dataset, the input is the json annotation file of the dataset split.\n",
    "In this example, `instances_val2017.json` is the annotation file of validation split of COCO17 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6127535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"coco17/annotations/instances_val2017.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b38ec9e",
   "metadata": {},
   "source": [
    "To evaluate the pretrained YOLOv3 model we loaded, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7662a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ec7e64",
   "metadata": {},
   "source": [
    "And the evaluation results are shown in command line output. The first value `0.223` is mAP in COCO standard, and the second one `0.420` is mAP in VOC standard (or mAP50). For more details about these metrics, see [COCO's evaluation guideline](https://cocodataset.org/#detection-eval)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa996e12",
   "metadata": {},
   "outputs": [],
   "source": [
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.223\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.420\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.215\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.060\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.237\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.358\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.215\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.333\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.137\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.385\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.529\n",
    "time usage: 81.76"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608ff205",
   "metadata": {},
   "source": [
    "YOLOv3 is small and fast. For larger model with higher performance, see :ref:`sec_automm_detection_eval_fasterrcnn_coco` or :ref:`sec_automm_detection_eval_ddetr_coco`.\n",
    "You can also see other tutorials for \\[Fast Finetune on COCO format data] or \\[Inference on COCO format data (with Visualization)].\n",
    "\n",
    "### Other Examples\n",
    "\n",
    "You may go to [AutoMM Examples](https://github.com/awslabs/autogluon/tree/master/examples/automm) to explore other examples about AutoMM.\n",
    "\n",
    "### Customization\n",
    "To learn how to customize AutoMM, please refer to :ref:`sec_automm_customization`.\n",
    "\n",
    "### Citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063bd652",
   "metadata": {},
   "outputs": [],
   "source": [
    "@misc{redmon2018yolov3,\n",
    "    title={YOLOv3: An Incremental Improvement},\n",
    "    author={Joseph Redmon and Ali Farhadi},\n",
    "    year={2018},\n",
    "    eprint={1804.02767},\n",
    "    archivePrefix={arXiv},\n",
    "    primaryClass={cs.CV}\n",
    "}"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
