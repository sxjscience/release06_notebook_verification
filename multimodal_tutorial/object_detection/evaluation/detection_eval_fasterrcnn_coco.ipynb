{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87700362",
   "metadata": {},
   "source": [
    "# AutoMM Detection - Evaluate Pretrained Faster R-CNN on COCO Format Dataset\n",
    ":label:`sec_automm_detection_eval_fasterrcnn_coco`\n",
    "\n",
    "[COCO](https://cocodataset.org/#home) is a large-scale object detection, segmentation, and captioning dataset. \n",
    "This tutorial will walk through the steps of preparing this dataset for Autogluon MultiModalPredictor.\n",
    "\n",
    "To start, let's import MultiModalPredictor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cc9ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e901451",
   "metadata": {},
   "source": [
    "We select the Faster R-CNN with ResNet50 as backbone and Feature Pyramid Network (FPN) as neck,\n",
    "this model has **23.9 frames per second (FPS)** on single A10e GPU with `batch_size=1`.\n",
    "For details about model selection, see :ref:`sec_automm_detection_select_models`.\n",
    "And we still use all the GPUs (if any):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfb9f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = \"faster_rcnn_r50_fpn_2x_coco\"\n",
    "num_gpus = -1  # use all GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c668fb",
   "metadata": {},
   "source": [
    "As before, we create the MultiModalPredictor with selected checkpoint name and number of GPUs.\n",
    "We also need to specify the problem_type to `\"object_detection\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9567a20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = MultiModalPredictor(\n",
    "    hyperparameters={\n",
    "        \"model.mmdet_image.checkpoint_name\": checkpoint_name,\n",
    "        \"env.num_gpus\": num_gpus,\n",
    "    },\n",
    "    problem_type=\"object_detection\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd85eb27",
   "metadata": {},
   "source": [
    "Here we use COCO17 for testing. \n",
    "See other tutorials for \\[Prepare COCO2017], \\[Convert VOC Format Dataset to COCO Format], and \\[Create Custom Dataset].\n",
    "While using COCO dataset, the input is the json annotation file of the dataset split.\n",
    "In this example, `instances_val2017.json` is the annotation file of validation split of COCO17 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef31fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"coco17/annotations/instances_val2017.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283240a5",
   "metadata": {},
   "source": [
    "To evaluate the pretrained Faster R-CNN model we loaded, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0326fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c485d7",
   "metadata": {},
   "source": [
    "And the evaluation results are shown in command line output. The first value `0.385` is mAP in COCO standard, and the second one `0.591` is mAP in VOC standard (or mAP50). For more details about these metrics, see [COCO's evaluation guideline](https://cocodataset.org/#detection-eval)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2b4f29",
   "metadata": {},
   "outputs": [],
   "source": [
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.385\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.591\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.421\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.422\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.505\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.319\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.500\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.521\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.326\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.558\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.667\n",
    "time usage: 257.45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb29e8bc",
   "metadata": {},
   "source": [
    "Faster R-CNN balances speed and performance. \n",
    "But in case that faster speed or higher performance is required, \n",
    "see :ref:`sec_automm_detection_eval_yolov3_coco` for faster speed,\n",
    "or :ref:`sec_automm_detection_eval_ddetr_coco` for higher performance.\n",
    "You can also see other tutorials for \\[Fast Finetune on COCO format data] or \\[Inference on COCO format data (with Visualization)].\n",
    "\n",
    "### Other Examples\n",
    "\n",
    "You may go to [AutoMM Examples](https://github.com/awslabs/autogluon/tree/master/examples/automm) to explore other examples about AutoMM.\n",
    "\n",
    "### Customization\n",
    "To learn how to customize AutoMM, please refer to :ref:`sec_automm_customization`.\n",
    "\n",
    "### Citation\n",
    "```\n",
    "@article{Ren_2017,\n",
    "   title={Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},\n",
    "   journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},\n",
    "   publisher={Institute of Electrical and Electronics Engineers (IEEE)},\n",
    "   author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},\n",
    "   year={2017},\n",
    "   month={Jun},\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
