{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6857652b",
   "metadata": {},
   "source": [
    "# Knowledge Distillation in AutoMM\n",
    ":label:`sec_automm_distillation_multilingual`\n",
    "\n",
    "Pretrained foundation models are becoming increasingly large. However, these models are difficult to deploy due to \n",
    "limited resources available in deployment scenarios. To benefit from large models under this constraint, \n",
    "you transfer the knowledge from the large-scale teacher models to the student model, with knowledge distillation.\n",
    "In this way, the small student model can be practically deployed under real-world scenarios,\n",
    "while the performance will be better than training the student model from scratch thanks to the teacher.\n",
    "\n",
    "In this tutorial, we introduce how to adopt `MultiModalPredictor` for knowledge distillation. For the purpose of demonstration, we use the [Question-answering NLI](https://paperswithcode.com/dataset/qnli) dataset, \n",
    "which comprises 104,743 question, answer pairs sampled from question answering datasets. We will demonstrate how to use a large model to guide the learning and improve the performance of a small model in AutoGluon.\n",
    "\n",
    "## Load Dataset\n",
    "\n",
    "The [Question-answering NLI](https://paperswithcode.com/dataset/qnli) dataset contains \n",
    "sentence pairs in English. In the label column, `0` means that the sentence is not related to the question and `1` means that the sentence is related to the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "776a54bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/ubuntu/.cache/huggingface/datasets/glue/qnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01561594009399414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 60,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f080468d314e8fb2ad1086b08870b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"glue\", \"qnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5040e677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'sentence', 'label', 'idx'],\n",
       "    num_rows: 104743\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a48cf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_valid_df = dataset[\"train\"].to_pandas()[[\"question\", \"sentence\", \"label\"]].sample(1000, random_state=123)\n",
    "train_df, valid_df = train_test_split(train_valid_df, test_size=0.2)\n",
    "test_df = dataset[\"validation\"].to_pandas()[[\"question\", \"sentence\", \"label\"]].sample(1000, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd9923",
   "metadata": {},
   "source": [
    "## Load the Teacher Model\n",
    "\n",
    "In our example, we will directly load a teacher model with the [google/bert_uncased_L-12_H-768_A-12](https://huggingface.co/google/bert_uncased_L-12_H-768_A-12) backbone that has been trained on QNLI and distill it into a student model with the [google/bert_uncased_L-6_H-768_A-12](https://huggingface.co/google/bert_uncased_L-6_H-768_A-12) backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9521c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --quiet https://automl-mm-bench.s3.amazonaws.com/unit-tests/distillation_sample_teacher.zip -O distillation_sample_teacher.zip\n",
    "!unzip -q -o distillation_sample_teacher.zip -d ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efb32aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/xjshi_dev/lib/python3.9/site-packages/horovod/common/util.py:258: UserWarning: Framework pytorch installed with version 1.12.0 but found version 1.12.1+cu116.\n",
      "             This can result in unexpected behavior including runtime errors.\n",
      "             Reinstall Horovod using `pip install --no-cache-dir` to build with the new version.\n",
      "  warnings.warn(get_version_mismatch_message(name, version, installed_version))\n",
      "/home/ubuntu/.conda/envs/xjshi_dev/lib/python3.9/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/home/ubuntu/.conda/envs/xjshi_dev/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor\n",
    "\n",
    "teacher_predictor = MultiModalPredictor.load(\"ag_distillation_sample_teacher/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5852d7",
   "metadata": {},
   "source": [
    "## Distill to Student\n",
    "\n",
    "Training the student model is straight forward. You may just add the `teacher_predictor` argument when calling `.fit()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95ed31e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n",
      "/home/ubuntu/.conda/envs/xjshi_dev/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ubuntu/.conda/envs/xjshi_dev/lib/python3.9/site-packages/pytorch_lightning/utilities/parsing.py:268: UserWarning: Attribute 'softmax_regression_loss_func' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['softmax_regression_loss_func'])`.\n",
      "  rank_zero_warn(\n",
      "/home/ubuntu/xjshi/autogluon/multimodal/src/autogluon/multimodal/utils/environment.py:61: UserWarning: Interactive environment is detected. Currently, MultiModalPredictor does not support multi-gpu training under an interactive environment due to the limitation of ddp / ddp_spawn strategies in PT Lightning. Thus, we switch to single gpu training. For multi-gpu training, you need to execute MultiModalPredictor in a script.\n",
      "  warnings.warn(\n",
      "Auto select gpus: [0]\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name                         | Type                         | Params\n",
      "------------------------------------------------------------------------------\n",
      "0 | student_model                | HFAutoModelForTextPrediction | 67.0 M\n",
      "1 | teacher_model                | HFAutoModelForTextPrediction | 109 M \n",
      "2 | validation_metric            | AUROC                        | 0     \n",
      "3 | hard_label_loss_func         | CrossEntropyLoss             | 0     \n",
      "4 | soft_label_loss_func         | CrossEntropyLoss             | 0     \n",
      "5 | softmax_regression_loss_func | MSELoss                      | 0     \n",
      "6 | output_feature_loss_func     | MSELoss                      | 0     \n",
      "7 | output_feature_adaptor       | Identity                     | 0     \n",
      "8 | rkd_loss_func                | RKDLoss                      | 0     \n",
      "------------------------------------------------------------------------------\n",
      "176 M     Trainable params\n",
      "0         Non-trainable params\n",
      "176 M     Total params\n",
      "352.881   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01564192771911621,
       "initial": 0,
       "n": 0,
       "ncols": 141,
       "nrows": 60,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014344930648803711,
       "initial": 0,
       "n": 0,
       "ncols": 141,
       "nrows": 60,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960c84dac2fe48c4b6bc8204d04854e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014075279235839844,
       "initial": 0,
       "n": 0,
       "ncols": 141,
       "nrows": 60,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 3: 'val_roc_auc' reached 0.66559 (best 0.66559), saving model to '/home/ubuntu/xjshi/autogluon/docs/tutorials/multimodal/advanced_topics/AutogluonModels/ag-20221115_092236/epoch=0-step=3.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013635396957397461,
       "initial": 0,
       "n": 0,
       "ncols": 141,
       "nrows": 60,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 7: 'val_roc_auc' reached 0.77510 (best 0.77510), saving model to '/home/ubuntu/xjshi/autogluon/docs/tutorials/multimodal/advanced_topics/AutogluonModels/ag-20221115_092236/epoch=0-step=7.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014005422592163086,
       "initial": 0,
       "n": 0,
       "ncols": 141,
       "nrows": 60,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 10: 'val_roc_auc' reached 0.78236 (best 0.78236), saving model to '/home/ubuntu/xjshi/autogluon/docs/tutorials/multimodal/advanced_topics/AutogluonModels/ag-20221115_092236/epoch=1-step=10.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01419830322265625,
       "initial": 0,
       "n": 0,
       "ncols": 141,
       "nrows": 60,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 14: 'val_roc_auc' reached 0.78215 (best 0.78236), saving model to '/home/ubuntu/xjshi/autogluon/docs/tutorials/multimodal/advanced_topics/AutogluonModels/ag-20221115_092236/epoch=1-step=14.ckpt' as top 3\n",
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014183759689331055,
       "initial": 0,
       "n": 0,
       "ncols": 141,
       "nrows": 60,
       "postfix": null,
       "prefix": "Predicting",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9d13052f46243df8fd3038ecadd6ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014002084732055664,
       "initial": 0,
       "n": 0,
       "ncols": 141,
       "nrows": 60,
       "postfix": null,
       "prefix": "Predicting",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b71bb143fc749a485cbe76f80504d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01411294937133789,
       "initial": 0,
       "n": 0,
       "ncols": 141,
       "nrows": 60,
       "postfix": null,
       "prefix": "Predicting",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "895c05d345d24f118795c25535ea0900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014295101165771484,
       "initial": 0,
       "n": 0,
       "ncols": 141,
       "nrows": 60,
       "postfix": null,
       "prefix": "Predicting",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed4111a847b4f5ea510e6618a0dace2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.multimodal.predictor.MultiModalPredictor at 0x7f4fbd36ea00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_predictor = MultiModalPredictor(label=\"label\")\n",
    "student_predictor.fit(\n",
    "    train_df,\n",
    "    tuning_data=valid_df,\n",
    "    teacher_predictor=teacher_predictor,\n",
    "    hyperparameters={\n",
    "        \"model.hf_text.checkpoint_name\": \"google/bert_uncased_L-6_H-768_A-12\",\n",
    "        \"optimization.max_epochs\": 2,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eb30579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014435768127441406,
       "initial": 0,
       "n": 0,
       "ncols": 141,
       "nrows": 60,
       "postfix": null,
       "prefix": "Predicting",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c2345f0fcf46dc9f8ea39a1bfbaefe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roc_auc': 0.7796779677967796}\n"
     ]
    }
   ],
   "source": [
    "print(student_predictor.evaluate(data=test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd2f22e",
   "metadata": {},
   "source": [
    "## Comparing with Direct Finetuning\n",
    "\n",
    "We then finetune a small model [mMiniLMv2](https://arxiv.org/abs/2012.15828) without distillation. \n",
    "We can still load the multilingual MiniLMv2 model from Huggingface/Transformers, \n",
    "with the key as [nreimers/mMiniLMv2-L6-H384-distilled-from-XLMR-Large](ahttps://huggingface.co/nreimers/mMiniLMv2-L6-H384-distilled-from-XLMR-Large). \n",
    "To simplify the experiment, we also just finetune for 4 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f36c3f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n",
      "/home/ubuntu/.conda/envs/xjshi_dev/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ubuntu/xjshi/autogluon/multimodal/src/autogluon/multimodal/utils/environment.py:61: UserWarning: Interactive environment is detected. Currently, MultiModalPredictor does not support multi-gpu training under an interactive environment due to the limitation of ddp / ddp_spawn strategies in PT Lightning. Thus, we switch to single gpu training. For multi-gpu training, you need to execute MultiModalPredictor in a script.\n",
      "  warnings.warn(\n",
      "Auto select gpus: [0]\n",
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name              | Type                         | Params\n",
      "-------------------------------------------------------------------\n",
      "0 | model             | HFAutoModelForTextPrediction | 67.0 M\n",
      "1 | validation_metric | AUROC                        | 0     \n",
      "2 | loss_func         | CrossEntropyLoss             | 0     \n",
      "-------------------------------------------------------------------\n",
      "67.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "67.0 M    Total params\n",
      "133.913   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015152454376220703,
       "initial": 0,
       "n": 0,
       "ncols": 141,
       "nrows": 60,
       "postfix": null,
       "prefix": "Sanity Checking",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013437509536743164,
       "initial": 0,
       "n": 0,
       "ncols": 141,
       "nrows": 60,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c440d6d447e54a18b547facbdbba7281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013889789581298828,
       "initial": 0,
       "n": 0,
       "ncols": 141,
       "nrows": 60,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 3: 'val_roc_auc' reached 0.64551 (best 0.64551), saving model to '/home/ubuntu/xjshi/autogluon/docs/tutorials/multimodal/advanced_topics/AutogluonModels/ag-20221115_092404/epoch=0-step=3.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013718843460083008,
       "initial": 0,
       "n": 0,
       "ncols": 141,
       "nrows": 60,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 7: 'val_roc_auc' reached 0.75955 (best 0.75955), saving model to '/home/ubuntu/xjshi/autogluon/docs/tutorials/multimodal/advanced_topics/AutogluonModels/ag-20221115_092404/epoch=0-step=7.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013933181762695312,
       "initial": 0,
       "n": 0,
       "ncols": 141,
       "nrows": 60,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 10: 'val_roc_auc' reached 0.77047 (best 0.77047), saving model to '/home/ubuntu/xjshi/autogluon/docs/tutorials/multimodal/advanced_topics/AutogluonModels/ag-20221115_092404/epoch=1-step=10.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01385498046875,
       "initial": 0,
       "n": 0,
       "ncols": 141,
       "nrows": 60,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 14: 'val_roc_auc' reached 0.76861 (best 0.77047), saving model to '/home/ubuntu/xjshi/autogluon/docs/tutorials/multimodal/advanced_topics/AutogluonModels/ag-20221115_092404/epoch=1-step=14.ckpt' as top 3\n",
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014075994491577148,
       "initial": 0,
       "n": 0,
       "ncols": 141,
       "nrows": 60,
       "postfix": null,
       "prefix": "Predicting",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1bd2a682454caabdd22f7a8e6aeeb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014309883117675781,
       "initial": 0,
       "n": 0,
       "ncols": 141,
       "nrows": 60,
       "postfix": null,
       "prefix": "Predicting",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b34ea6e45e4ae78ed4c868799a4cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014246940612792969,
       "initial": 0,
       "n": 0,
       "ncols": 141,
       "nrows": 60,
       "postfix": null,
       "prefix": "Predicting",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0cfd38057d4d9c8635f42936c4185a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014211654663085938,
       "initial": 0,
       "n": 0,
       "ncols": 141,
       "nrows": 60,
       "postfix": null,
       "prefix": "Predicting",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8ca12b62a34b97ab0da212dc56bcba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.multimodal.predictor.MultiModalPredictor at 0x7f4f3c303cd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodistill_predictor = MultiModalPredictor(label=\"label\")\n",
    "nodistill_predictor.fit(\n",
    "    train_df,\n",
    "    tuning_data=valid_df,\n",
    "    hyperparameters={\n",
    "        \"model.hf_text.checkpoint_name\": \"google/bert_uncased_L-6_H-768_A-12\",\n",
    "        \"optimization.max_epochs\": 2,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "016b2002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014445304870605469,
       "initial": 0,
       "n": 0,
       "ncols": 141,
       "nrows": 60,
       "postfix": null,
       "prefix": "Predicting",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367d3c92f95a422d9d09bce07f50b8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roc_auc': 0.7889288928892888}\n"
     ]
    }
   ],
   "source": [
    "print(nodistill_predictor.evaluate(data=test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869fbe78",
   "metadata": {},
   "source": [
    "We can find that via knowledge distillation, the performance of `student_predictor` is better than `nodistill_predictor`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a1eb25",
   "metadata": {},
   "source": [
    "## More about Knowledge Distillation\n",
    "\n",
    "To learn how to customize distillation, see the distillation examples \n",
    "and README in [AutoMM Distillation Examples](https://github.com/awslabs/autogluon/tree/master/examples/automm/distillation).\n",
    "Especially the [multilingual distillation example](https://github.com/awslabs/autogluon/tree/master/examples/automm/distillation/automm_distillation_pawsx.py) with more details and customization.\n",
    "\n",
    "## Other Examples\n",
    "\n",
    "You may go to [AutoMM Examples](https://github.com/awslabs/autogluon/tree/master/examples/automm) to explore other examples about AutoMM.\n",
    "\n",
    "## Customization\n",
    "To learn how to customize AutoMM, please refer to :ref:`sec_automm_customization`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
